# DTN AI Server Configuration
# Maps model names to their processor modules

models:
  # model api: api.system.llm-simpletext: string[] -> string
  - model: "model.system.openai-gpt-5"
    processor: "processor_gpt_o3"
  - model: "model.system.openai-gpt-5-mini"
    processor: "processor_gpt_o3"
  - model: "model.system.openai-gpt-5-nano"
    processor: "processor_gpt_o3"
  
  # model api: api.system.llm-simpleimage: string[], uint64, uint64 -> bytes
  - model: "model.system.openai-gpt-image-1"
    processor: "processor_gpt_o3"

  # Add more models as needed
  - model: "model.system.google-gemini-2_5-pro"
    processor: "processor_gemini"
  - model: "model.system.google-gemini-2_5-flash"
    processor: "processor_gemini"
  - model: "model.system.google-gemini-2_5-flash-lite"
    processor: "processor_gemini"
